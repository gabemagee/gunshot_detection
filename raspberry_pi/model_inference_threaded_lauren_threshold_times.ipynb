{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiprocess inference: \n",
    "    #there is one analyze process running throughohut the duration of the program\n",
    "        #main adds the microphone_data to a queue which analyze gets from the queue and analyzes\n",
    "    #there is also one sms process running throughout the duration of the program\n",
    "        #if a gunshot is detected w prob > 90%, a 1 is added to a queue which the sms alert process will\n",
    "        #take as a sign to send a text\n",
    "\n",
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import multiprocessing\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from multiprocessing import Process, active_children\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "#from gsmmodem.modem import GsmModem\n",
    "import time\n",
    "import soundfile as sf\n",
    "from array import array\n",
    "from sys import byteorder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream_handler = logging.StreamHandler(sys.stdout)\n",
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('spam.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the pi, change to paInt16\n",
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 22050\n",
    "audio_sample_duration = 2\n",
    "input_shape = (audio_rate, 1)\n",
    "phone_numbers_to_message = [\"8163449956\", \"9176202840\", \"7857642331\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization function\n",
    "def normalize(sound_data):\n",
    "    # Averages the volume out\n",
    "    sound_normalization_threshold = 16384\n",
    "    times = float(sound_normalization_threshold) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * times))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 1: Analuze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads model\n",
    "#if microphone data reaches a threshold, predicts with the model\n",
    "#if model predicts a gunshot, send a text, and add data to the time localization queue\n",
    "\n",
    "def analyze_microphone_data(audio_rate, ):\n",
    "\n",
    "    #LOAD THE MODEL\n",
    "    def auc(y_true, y_pred):\n",
    "        auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        return auc\n",
    "\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate=drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate=(drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1028, activation=\"relu\")(x)\n",
    "    output_tensor = layers.Dense(number_of_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=metrics)\n",
    "    \n",
    "    model.load_weights(\"./models/gunshot_sound_model.h5\")\n",
    "\n",
    "    \n",
    "    #infinite loop\n",
    "    while True:\n",
    "        #will wait until something is in the queue to continue\n",
    "        microphone_data = audio_analysis_queue.get()\n",
    "        time_of_sample = audio_analysis_queue.get()\n",
    "        \n",
    "        # Performs post-processing on live audio samples\n",
    "        reformed_microphone_data = librosa.resample(y=microphone_data, orig_sr=audio_rate, target_sr=22050)\n",
    "        reformed_microphone_data = normalize(reformed_microphone_data)\n",
    "        reformed_microphone_data = reformed_microphone_data[:audio_rate]\n",
    "        reformed_microphone_data = reformed_microphone_data.reshape(-1, audio_rate, 1)\n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(reformed_microphone_data)\n",
    "        emit_string = \"Probabilities derived by the model: \" + str(probabilities)\n",
    "        logger.debug(emit_string)\n",
    "\n",
    "        #send a text if gunshot if detected\n",
    "        if (probabilities[0][1] >= 0.9):\n",
    "            sms_alert_queue.put(\"1\")\n",
    "            time_localization_queue.put(reformed_microphone_data.reshape(44100))\n",
    "            time_localization_queue.put(time_of_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 3: Figure out exact time of gunshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from the time localization queue\n",
    "#use a threshold in the data to figure out where the spikes (gunshots) are at in the clip\n",
    "\n",
    "def localize_time():\n",
    "    \n",
    "    #infinite loop\n",
    "    while True:\n",
    "        #get data and time at beginning of data chunk\n",
    "        mic_data = time_localization_queue.get()\n",
    "        time_at_beg = time_localization_queue.get()\n",
    "\n",
    "        #sort the data, figure out the threshold\n",
    "        sorted_data = np.sort(mic_data)\n",
    "        threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "        #find all values above that threshold\n",
    "        above_threshold = []\n",
    "        for i in range(0, len(mic_data)):\n",
    "            if mic_data[i] > threshold:\n",
    "                above_threshold.append(i)\n",
    "                \n",
    "        #separate out individual gunshots from that whole chunk\n",
    "        distinct_shots = []\n",
    "        distinct_shots.append(above_threshold[0])\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            \n",
    "            if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "                distinct_shots.append(above_threshold[i])\n",
    "\n",
    "        logger.debug(\"There were \" + str(len(distinct_shots)) + \" distinct shots detected at \" + str(time.ctime(time_at_beg)))\n",
    "        for i in distinct_shots:\n",
    "            logger.debug(i/22050)\n",
    "            \n",
    "        logger.debug(\"These \")\n",
    "\n",
    "        #write out a soundfile of the entire chunk\n",
    "        with sf.SoundFile(\"/Users/laurenogden/Downloads/\" + str(time.ctime(time_at_beg)) + \".wav\", mode='wb', samplerate=22050, channels=1) as file:\n",
    "            file.write(mic_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 2: Send SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send an sms if a gunshot is detected\n",
    "\n",
    "def send_sms_alert(phone_numbers_to_message, ):\n",
    "    \n",
    "    # Modem variables\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None # SIM card PIN (if any)\n",
    "    \n",
    "    # Connect to the modem\n",
    "    #print(\"Initializing connection to modem...\")\n",
    "    #modem = GsmModem(modem_port, modem_baudrate)\n",
    "    #modem.smsTextMode = False\n",
    "    #modem.connect(modem_sim_pin)\n",
    "    \n",
    "    \n",
    "    # If the model detects a gunshot, an SMS alert will be sent to local authorities\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"1\":\n",
    "            logger.debug(\"~~~~~~~~pretend like I just sent a text message~~~~~~~~~~\")\n",
    "            '''\n",
    "            try:\n",
    "                modem.waitForNetworkCoverage(timeout=86400)\n",
    "                message = \" (Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in phone_numbers_to_message:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" * Finished evaluating an audio sample with the model * \")\n",
    "            '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process: Capture Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the stream\n",
    "pa = pyaudio.PyAudio()\n",
    "    \n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "3324\n",
      "13369\n",
      "6518\n",
      "7871\n",
      "7734\n",
      "11456\n",
      "13564\n",
      "10270\n",
      "12555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-7:\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-16-5fbb142516d8>\", line 55, in analyze_microphone_data\n",
      "    microphone_data = audio_analysis_queue.get()\n",
      "  File \"<ipython-input-17-63e9285d6735>\", line 9, in localize_time\n",
      "    mic_data = time_localization_queue.get()\n",
      "  File \"<ipython-input-18-a0c8f26659eb>\", line 19, in send_sms_alert\n",
      "    sms_alert_status = sms_alert_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-569d310b20ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Loops through the stream and appends audio chunks to the frame array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0maudio_frames_per_buffer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maudio_sample_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_frames_per_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#if on the pi, change dtype to int16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mnp_array_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #Create the Queues\n",
    "    sms_alert_queue = multiprocessing.Queue()\n",
    "    audio_analysis_queue = multiprocessing.Queue()\n",
    "    time_localization_queue = multiprocessing.Queue()\n",
    "    \n",
    "    #Create Analysis Process\n",
    "    analysis_process = Process(target = analyze_microphone_data, args = (audio_rate, ))\n",
    "    analysis_process.start()\n",
    "    \n",
    "    #Create SMS Process\n",
    "    sms_alert_process = Process(target = send_sms_alert, args = (phone_numbers_to_message, ))\n",
    "    sms_alert_process.start()\n",
    "    \n",
    "    #Create process for localization\n",
    "    time_localization_process = Process(target = localize_time, args = ())\n",
    "    time_localization_process.start()\n",
    "    \n",
    "\n",
    "    logger.debug(\"----------------------------------- RECORDING AUDIO -------------------------------------------\")\n",
    "    \n",
    "    while(True):\n",
    "        np_array_data = []\n",
    "        \n",
    "        now = time.time()\n",
    "\n",
    "        # Loops through the stream and appends audio chunks to the frame array\n",
    "        for i in range(0, int(audio_rate / audio_frames_per_buffer * audio_sample_duration)):\n",
    "            data = stream.read(audio_frames_per_buffer, exception_on_overflow = False)\n",
    "            #if on the pi, change dtype to int16\n",
    "            np_array_data.append(np.frombuffer(data, dtype=np.int16))\n",
    "        microphone_data = np.concatenate(np_array_data)\n",
    "        #emit_string = \"Cumulative length of a given two-second audio sample: \" + str(len(microphone_data))\n",
    "        #logger.debug(emit_string)\n",
    "        #emit_string = \"The maximum frequency value for a given two-second audio sample: \" + str(max(microphone_data))\n",
    "        #logger.debug(emit_string)\n",
    "        \n",
    "        \n",
    "        # put microphone data on the queue to go to the analysis process\n",
    "            # the analysis process will check the threshold: if max(microphone_data) >= 1000:\n",
    "        audio_analysis_queue.put(microphone_data)\n",
    "        #also put time: for localization\n",
    "        audio_analysis_queue.put(now)\n",
    "\n",
    "        \n",
    "        # Closes all finished processes    \n",
    "        kids = active_children()\n",
    "        #logger.debug(\"these are my active children: \")\n",
    "        #logger.debug(kids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
