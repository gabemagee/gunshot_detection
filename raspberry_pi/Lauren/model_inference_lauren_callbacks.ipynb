{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/core/audio.py:37: UserWarning: Could not import scikits.samplerate. Falling back to scipy.signal\n",
      "  warnings.warn('Could not import scikits.samplerate. '\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/display.py:32: MatplotlibDeprecationWarning: \n",
      "The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory.\n",
      "  mpl.rcParams.update(**_matplotlibrc)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The examples.directory rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2. In the future, examples will be found relative to the 'datapath' directory.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The text.latex.unicode rcparam was deprecated in Matplotlib 3.0 and will be removed in 3.2.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_collections_abc.py:849: MatplotlibDeprecationWarning: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "  self[key] = value\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n"
     ]
    }
   ],
   "source": [
    "#Edited from model_inference_alex.ipynb\n",
    "    #uses threads (instead of processes) and the callback version of pyaudio instead of blocking\n",
    "    #https://www.dlology.com/blog/how-to-do-real-time-trigger-word-detection-with-keras/\n",
    "    #based off of ^^ link, instead of analyzing discrete 2 second chunks, does sliding predictions each half a sec\n",
    "\n",
    "\n",
    "import pyaudio\n",
    "import librosa\n",
    "import logging\n",
    "import time\n",
    "import wave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from threading import Thread\n",
    "from array import array\n",
    "from scipy.io import wavfile\n",
    "from queue import Queue\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Input, layers, optimizers, backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from gsmmodem.modem import GsmModem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('debugger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.FileHandler('output.log')\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_format = pyaudio.paInt16\n",
    "audio_rate = 44100\n",
    "audio_channels = 1\n",
    "audio_device_index = 0\n",
    "audio_frames_per_buffer = 4410\n",
    "audio_sample_duration = 2\n",
    "audio_analysis_queue = Queue()\n",
    "audio_analysis_time_queue = Queue()\n",
    "sound_data = np.zeros(0, dtype = \"int16\")\n",
    "audio_volume_threshold = 1000\n",
    "sms_alert_queue = Queue()\n",
    "inference_model_confidence_threshold = 0.95\n",
    "max_audio_frame_int_value = 2 ** 15 - 1\n",
    "sound_normalization_threshold = 10 ** (-1.0 / 20)\n",
    "designated_alert_recipients = [\"8163449956\", \"9176202840\", \"7857642331\"]\n",
    "\n",
    "localization_data_queue = Queue()\n",
    "localization_time_queue = Queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Augmented Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/alexm/Datasets/gunshot_augmented_sound_labels.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5cccd13acfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/alexm/Datasets/gunshot_augmented_sound_labels.npy'"
     ]
    }
   ],
   "source": [
    "labels = np.load(\"/home/alexm/Datasets/gunshot_augmented_sound_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    normalization_factor = float(sound_normalization_threshold * max_audio_frame_int_value) / max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('h')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa Wrapper Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft(y, n_fft, hop_length, win_length):\n",
    "    return librosa.stft(y = y, n_fft = n_fft, hop_length = hop_length, win_length = win_length)\n",
    "\n",
    "\n",
    "def _istft(y, hop_length, win_length):\n",
    "    return librosa.istft(y, hop_length, win_length)\n",
    "\n",
    "\n",
    "def _amp_to_db(x):\n",
    "    return librosa.core.logamplitude(x, ref_power = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.amplitude_to_db(x, ref = 1.0, amin = 1e-20, top_db = 80.0)  # Librosa 0.6.3 functionality\n",
    "\n",
    "\n",
    "def _db_to_amp(x):\n",
    "    return librosa.core.perceptual_weighting(x, frequencies = 1.0)  # Librosa 0.4.2 functionality\n",
    "#     return librosa.core.db_to_amplitude(x, ref = 1.0)  # Librosa 0.6.3 functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Noise Reduction Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(audio_clip,\n",
    "                noise_clip,\n",
    "                n_grad_freq = 2,\n",
    "                n_grad_time = 4,\n",
    "                n_fft = 2048,\n",
    "                win_length = 2048,\n",
    "                hop_length = 512,\n",
    "                n_std_thresh = 1.5,\n",
    "                prop_decrease = 1.0,\n",
    "                verbose = False,\n",
    "                visual = False):\n",
    "    \n",
    "    \"\"\" Removes noise from audio based upon a clip containing only noise\n",
    "\n",
    "    Args:\n",
    "        audio_clip (array): The first parameter.\n",
    "        noise_clip (array): The second parameter.\n",
    "        n_grad_freq (int): how many frequency channels to smooth over with the mask.\n",
    "        n_grad_time (int): how many time channels to smooth over with the mask.\n",
    "        n_fft (int): number audio of frames between STFT columns.\n",
    "        win_length (int): Each frame of audio is windowed by `window()`. The window will be of length `win_length` and then padded with zeros to match `n_fft`..\n",
    "        hop_length (int):number audio of frames between STFT columns.\n",
    "        n_std_thresh (int): how many standard deviations louder than the mean dB of the noise (at each frequency level) to be considered signal\n",
    "        prop_decrease (float): To what extent should you decrease noise (1 = all, 0 = none)\n",
    "        visual (bool): Whether to plot the steps of the algorithm\n",
    "\n",
    "    Returns:\n",
    "        array: The recovered signal with noise subtracted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the noise sample\n",
    "    noise_stft = _stft(noise_clip, n_fft, hop_length, win_length)\n",
    "    noise_stft_db = _amp_to_db(np.abs(noise_stft))  # Converts the sample units to dB\n",
    "    \n",
    "    # Calculates statistics over the noise sample\n",
    "    mean_freq_noise = np.mean(noise_stft_db, axis = 1)\n",
    "    std_freq_noise = np.std(noise_stft_db, axis = 1)\n",
    "    noise_thresh = mean_freq_noise + std_freq_noise * n_std_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on noise:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Takes a STFT over the signal sample\n",
    "    sig_stft = _stft(audio_clip, n_fft, hop_length, win_length)\n",
    "    sig_stft_db = _amp_to_db(np.abs(sig_stft))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"STFT on signal:\", td(seconds = time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Calculates value to which to mask dB\n",
    "    mask_gain_dB = np.min(_amp_to_db(np.abs(sig_stft)))\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Noise Threshold & Mask Gain in dB: \", noise_thresh, mask_gain_dB)\n",
    "    \n",
    "    # Creates a smoothing filter for the mask in time and frequency\n",
    "    smoothing_filter = np.outer(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_freq + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_freq + 2),\n",
    "            ]\n",
    "        )[1:-1],\n",
    "        np.concatenate(\n",
    "            [\n",
    "                np.linspace(0, 1, n_grad_time + 1, endpoint = False),\n",
    "                np.linspace(1, 0, n_grad_time + 2),\n",
    "            ]\n",
    "        )[1:-1]\n",
    "    )\n",
    "    \n",
    "    smoothing_filter = smoothing_filter / np.sum(smoothing_filter)\n",
    "    \n",
    "    # Calculates the threshold for each frequency/time bin\n",
    "    db_thresh = np.repeat(np.reshape(noise_thresh, [1, len(mean_freq_noise)]),\n",
    "                          np.shape(sig_stft_db)[1],\n",
    "                          axis = 0).T\n",
    "    \n",
    "    # Masks segment if the signal is above the threshold\n",
    "    sig_mask = sig_stft_db < db_thresh\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Masking:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Convolves the mask with a smoothing filter\n",
    "    sig_mask = scipy.signal.fftconvolve(sig_mask, smoothing_filter, mode=\"same\")\n",
    "    sig_mask = sig_mask * prop_decrease\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask convolution:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Masks the signal\n",
    "    sig_stft_db_masked = (sig_stft_db * (1 - sig_mask)\n",
    "                          + np.ones(np.shape(mask_gain_dB))\n",
    "                          * mask_gain_dB * sig_mask)  # Masks real\n",
    "    \n",
    "    sig_imag_masked = np.imag(sig_stft) * (1 - sig_mask)\n",
    "    sig_stft_amp = (_db_to_amp(sig_stft_db_masked) * np.sign(sig_stft)) + (1j * sig_imag_masked)\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Mask application:\", td(seconds=time.time() - start))\n",
    "        start = time.time()\n",
    "        \n",
    "    # Recovers the signal\n",
    "    recovered_signal = _istft(sig_stft_amp, hop_length, win_length)\n",
    "    recovered_spec = _amp_to_db(\n",
    "        np.abs(_stft(recovered_signal, n_fft, hop_length, win_length))\n",
    "    )\n",
    "    \n",
    "    # Debugging\n",
    "    if verbose:\n",
    "        print(\"Signal recovery:\", td(seconds=time.time() - start))\n",
    "        \n",
    "    # Returns noise-reduced audio sample\n",
    "    return recovered_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV File Composition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves a two-second gunshot sample as a WAV file\n",
    "def create_gunshot_wav_file(microphone_data, index, timestamp, number_of_audio_channels = audio_channels, sample_width = 2, frame_rate = 22050):\n",
    "    wav_file = wave.open(\"/Users/laurenogden/Downloads/\"\n",
    "                            + str(index) + \" (\"\n",
    "                            + str(timestamp) + \").wav\", \"wb\")\n",
    "    wav_file.setnchannels(number_of_audio_channels)\n",
    "    wav_file.setsampwidth(sample_width)\n",
    "    wav_file.setframerate(frame_rate)\n",
    "    wav_file.writeframes(microphone_data.reshape(44100))\n",
    "    wav_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Noise Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample_wav = \"/Users/laurenogden/Downloads/1562604212.175424.wav\"\n",
    "noise_sample_rate, noise_sample = wavfile.read(noise_sample_wav)\n",
    "noise_clip = noise_sample[14000:18000]  # Finding a clip with just noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Time-Series Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_one(weights_file):\n",
    "    # Initializing 1D Time-Series Model Parameters\n",
    "    drop_out_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    number_of_epochs = 100\n",
    "    number_of_classes = 2\n",
    "    batch_size = 32\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    input_shape = (44100, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 1D Time-Series Model\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(input_tensor)\n",
    "    x = layers.Conv1D(16, 9, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(16)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.MaxPool1D(4)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.Conv1D(256, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "    x = layers.GlobalMaxPool1D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = \"relu\")(x)\n",
    "    x = layers.Dense(1028, activation = \"relu\")(x)\n",
    "    \n",
    "    # Compiling 1D Time-Series Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "    \n",
    "    # Loading 1D Time-Series Model Weights\n",
    "    model.load_weights(weights_file)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Spectrogram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_two(weights_file):\n",
    "    # 2D Spectrogram Model Parameters\n",
    "    input_shape = (128, 87, 1)\n",
    "    input_tensor = Input(shape = input_shape)\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optimizers.Adam(learning_rate, learning_rate / 100)\n",
    "    filter_size = (3,3)\n",
    "    maxpool_size = (3,3)\n",
    "    activation = \"relu\"\n",
    "    drop_out_rate = 0.1\n",
    "    number_of_classes = 2\n",
    "    metrics = [auc, \"accuracy\"]\n",
    "    \n",
    "    # Reconstructing 2D Spectrogram Model\n",
    "    x = layers.Conv2D(16, filter_size, activation = activation, padding = \"same\")(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPool2D(maxpool_size)(x)\n",
    "    x = layers.Dropout(rate = drop_out_rate)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, filter_size, activation = activation, padding = \"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPool2D()(x)\n",
    "    x = layers.Dropout(rate = (drop_out_rate * 2))(x) # Increasing drop-out rate here to prevent overfitting\n",
    "\n",
    "    x = layers.Dense(64, activation = activation)(x)\n",
    "    x = layers.Dense(1028, activation = activation)(x)\n",
    "    \n",
    "    # Compiling 2D Spectrogram Model\n",
    "    output_tensor = layers.Dense(number_of_classes, activation = \"softmax\")(x)\n",
    "    spec_model = tf.keras.Model(input_tensor, output_tensor)\n",
    "    spec_model.compile(optimizer = optimizer, loss = keras.losses.binary_crossentropy, metrics = metrics)\n",
    "\n",
    "    # Loading 2D Spectrogram Model Weights\n",
    "    spec_model.load_weights(weights_file)\n",
    "    \n",
    "    return spec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreaded Inference: A callback thread adds 0.5 second samples of microphone data to the audio analysis queue; The main thread, an audio analysis thread, detects the presence of gunshot sounds in samples retrieved from the audio analysis queue; And an SMS alert thread dispatches groups of messages to designated recipients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS Alert Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms_alert():\n",
    "    # Continuously dispatches SMS alerts to a list of designated recipients\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            logger.debug(\"ALERT: A Gunshot Has Been Detected\")\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Configuring the Modem Connection\n",
    "    modem_port = '/dev/ttyUSB0'\n",
    "    modem_baudrate = 115200\n",
    "    modem_sim_pin = None  # SIM card PIN (if any)\n",
    "    \n",
    "    # Establishing a Connection to the SMS Modem\n",
    "    logger.debug(\"Initializing connection to modem...\")\n",
    "    modem = GsmModem(modem_port, modem_baudrate)\n",
    "    modem.smsTextMode = False\n",
    "    modem.connect(modem_sim_pin)\n",
    "    \n",
    "    # The SMS alert thread will run indefinitely\n",
    "    while True:\n",
    "        sms_alert_status = sms_alert_queue.get()\n",
    "        if sms_alert_status == \"Gunshot Detected\":\n",
    "            try:\n",
    "                # At this point in execution, an attempt to send an SMS alert to local authorities will be made\n",
    "                modem.waitForNetworkCoverage(timeout = 86400)\n",
    "                message = \"(Testing) ALERT: A Gunshot Has Been Detected (Testing)\"\n",
    "                for number in designated_alert_recipients:\n",
    "                    modem.sendSms(number, message)\n",
    "                logger.debug(\" *** Sent out an SMS alert to all designated recipients *** \")\n",
    "            except:\n",
    "                logger.debug(\"ERROR: Unable to successfully send an SMS alert to the designated recipients.\")\n",
    "                pass\n",
    "            finally:\n",
    "                logger.debug(\" ** Finished evaluating an audio sample with the model ** \")\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Localization Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from the time localization queue\n",
    "#writes out a wav file starting when a gunshot was detected and \n",
    "\n",
    "def localize():\n",
    "    \n",
    "    #variables\n",
    "    all_mic_data = []\n",
    "    #index of iteration\n",
    "    loop = 0\n",
    "    \n",
    "    #infinite loop\n",
    "    while True:\n",
    "        #get all the mic data from the queue and add it to the list\n",
    "        while True:\n",
    "            chunk = localization_data_queue.get()\n",
    "            if np.array_equal(chunk, (np.zeros((44100,), dtype = np.int16))):\n",
    "                logger.debug(\"    reached end of a gunshot group\")\n",
    "                break;\n",
    "            else:\n",
    "                all_mic_data.append(chunk) \n",
    "\n",
    "                \n",
    "        #get beginning of mic data times\n",
    "        time_at_beg_of_first_gunshot_clip = localization_time_queue.get()\n",
    "        \n",
    "        # processing\n",
    "        np_all_mic_data = np.concatenate(all_mic_data)\n",
    "        ref_all_mic_data = librosa.resample(y=np_all_mic_data, orig_sr=44100, target_sr=22050)\n",
    "        ref_all_mic_data = librosa.util.normalize(ref_all_mic_data)\n",
    "        \n",
    "        #write out a soundfile of the entire chunk\n",
    "        with sf.SoundFile(\"/Users/laurenogden/Downloads/\" + str(loop) + \"__\" + time.ctime(time_at_beg_of_first_gunshot_clip) + \".wav\", mode='wb', samplerate=22050, channels=1) as file:\n",
    "            file.write(ref_all_mic_data)\n",
    "        logger.debug(\"    wrote out the #\" + str(loop) + \"chunk, size: \" + str(len(ref_all_mic_data)))\n",
    "\n",
    " \n",
    "        #figure out the times of the gunshots in the clip\n",
    "        #sort the data, figure out the threshold\n",
    "        sorted_data = np.sort(ref_all_mic_data)\n",
    "        threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "        #find all values above that threshold\n",
    "        above_threshold = []\n",
    "        for i in range(0, len(ref_all_mic_data)):\n",
    "            if ref_all_mic_data[i] > threshold:\n",
    "                above_threshold.append(i)\n",
    "                \n",
    "        #separate out individual gunshots from that whole chunk\n",
    "        distinct_shots = []\n",
    "        distinct_shots.append(above_threshold[0])\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            #if within 5ms of each other, assume from same shot\n",
    "            if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "                distinct_shots.append(above_threshold[i])\n",
    "\n",
    "        #times relative to beginning of the saved clip\n",
    "        logger.debug(\"There were \" + str(len(distinct_shots)) + \" distinct shots detected at \" + str(time.ctime(time_at_beg_of_first_gunshot_clip)))\n",
    "        for i in distinct_shots:\n",
    "            logger.debug(i/22050)\n",
    "            \n",
    "        #times in general\n",
    "        #logger.debug(\"The exact times of the gunshots were: \")\n",
    "        #for i in distinct_shots:\n",
    "            #logger.debug(time_at_beg_of_first_gunshot_clip + i/22050 - 2)\n",
    "            #logger.debug(time.ctime(time_at_beg_of_first_gunshot_clip + i/22050 - 2))\n",
    "\n",
    "            \n",
    "        #clear all mic data to be ready for the next clip\n",
    "        del all_mic_data[:]\n",
    "        #increase index\n",
    "        loop += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global sound_data;\n",
    "    sound_buffer = np.frombuffer(in_data, dtype = \"int16\")\n",
    "    sound_data = np.append(sound_data, sound_buffer)\n",
    "    \n",
    "    #put each half a second on the queue\n",
    "    if len(sound_data) >= 22050:\n",
    "        audio_analysis_queue.put(sound_data)\n",
    "        #put the time on a separate queue\n",
    "        current_time = time.time()\n",
    "        audio_analysis_time_queue.put(current_time)\n",
    "        #empty out sound_data\n",
    "        sound_data = np.zeros(0, dtype = \"int16\")\n",
    "        \n",
    "\n",
    "    return (sound_buffer, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and Capturing the Microphone Audio Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "\n",
    "stream = pa.open(format = audio_format,\n",
    "                 rate = audio_rate,\n",
    "                 channels = audio_channels,\n",
    "                 input_device_index = audio_device_index,\n",
    "                 frames_per_buffer = audio_frames_per_buffer,\n",
    "                 input = True,\n",
    "                 stream_callback = callback)\n",
    "\n",
    "# Starts the callback thread\n",
    "stream.start_stream()\n",
    "logger.debug(\"--- Listening to Audio Stream ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Microphone Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-220ed43f81fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mmicrophone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmicrophone_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m#get a new half second from the queue to add onto the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mmicrophone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmicrophone_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_analysis_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"int16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;31m#get a new time for the new beginning from the time queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mtime_of_sample_occurrence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_analysis_time_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Starts the SMS alert thread\n",
    "sms_alert_thread = Thread(target = send_sms_alert)\n",
    "sms_alert_thread.start()\n",
    "\n",
    "#starting the time localization thread\n",
    "#time_localization_thread = Thread(target = localization)\n",
    "#time_localization_thread.start()\n",
    "\n",
    "# Loading 1D Time-Series Model\n",
    "model = load_model_one(\"../models/gunshot_sound_model.h5\")\n",
    "    \n",
    "# Loading 2D Spectrogram Model\n",
    "#   model = load_model_two(\"./models/gunshot_sound_model_spectrograph_model.h5\")\n",
    "    \n",
    "# An iterator variable for counting the number of gunshot sounds detected\n",
    "gunshot_sound_counter = 1\n",
    "\n",
    "#booleans for detection status\n",
    "detected = False\n",
    "detected_first = False\n",
    "detected_again = False\n",
    "end_of_detections = False\n",
    "\n",
    "# get the first 2 s long clip from the queue\n",
    "all_mic_data = []\n",
    "for i in range(0, 4):\n",
    "    all_mic_data.append(np.array(audio_analysis_queue.get(), dtype = \"int16\"))    \n",
    "#make it into a numpy array\n",
    "microphone_data = np.concatenate(all_mic_data)\n",
    "# and get the start time at the beg of those 2 secs\n",
    "time_of_sample_occurrence = audio_analysis_time_queue.get()\n",
    "\n",
    "times_of_shots = []\n",
    "\n",
    "# The main (audio analysis) thread will run indefinitely\n",
    "while True:\n",
    "\n",
    "    # Outputs the current sample's maximum frequency value\n",
    "    maximum_frequency_value = max(microphone_data)\n",
    "    logger.debug(\"The maximum frequency value of a given sample: \" + str(maximum_frequency_value))\n",
    "        \n",
    "    # Determines whether a given sample potentially contains a gunshot\n",
    "    if maximum_frequency_value >= audio_volume_threshold:\n",
    "        # Post-processes the microphone data\n",
    "        modified_microphone_data = librosa.resample(y = microphone_data, orig_sr = audio_rate, target_sr = 22050)\n",
    "        modified_microphone_data = normalize(modified_microphone_data)\n",
    "#         modified_microphone_data = remove_noise(audio_clip = modified_microphone_data, noise_clip = noise_clip)  # As a substitute for normalization\n",
    "#         number_of_missing_sample_hertz = 44100 - len(modified_microphone_data)\n",
    "#         if number_of_missing_sample_hertz > 0:\n",
    "#             modified_microphone_data = np.array(modified_microphone_data.tolist() + [0 for i in range(number_of_missing_sample_hertz)])\n",
    "        modified_microphone_data = modified_microphone_data[:44100]\n",
    "        modified_microphone_data = modified_microphone_data.reshape(-1, 44100, 1)\n",
    "\n",
    "        # Passes a given audio sample into the model for prediction\n",
    "        probabilities = model.predict(modified_microphone_data)\n",
    "        logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "        #logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])\n",
    "\n",
    "        # Determines if a gunshot sound was detected by the model\n",
    "        if (probabilities[0][1] >= inference_model_confidence_threshold):\n",
    "            \n",
    "            # Sends out an SMS alert\n",
    "            sms_alert_queue.put(\"Gunshot Detected\")\n",
    "\n",
    "            # Makes a WAV file of the gunshot sample\n",
    "            create_gunshot_wav_file(modified_microphone_data, gunshot_sound_counter, time_of_sample_occurrence)\n",
    "\n",
    "            # Increments the counter for gunshot sound file names\n",
    "            gunshot_sound_counter += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #time localization in here \n",
    "            #figure out the times of the gunshots in the clip\n",
    "            #sort the data, figure out the threshold\n",
    "            modified_microphone_data = modified_microphone_data.reshape(44100)\n",
    "            sorted_data = np.sort(modified_microphone_data)\n",
    "            threshold = sorted_data[len(sorted_data) - int(len(sorted_data)*0.001)]\n",
    "\n",
    "            #find all values above that threshold\n",
    "            above_threshold = []\n",
    "            for i in range(0, len(modified_microphone_data)):\n",
    "                if modified_microphone_data[i] > threshold:\n",
    "                    above_threshold.append(i)\n",
    "\n",
    "            #separate out individual gunshots from that whole chunk\n",
    "            distinct_shots = []\n",
    "            distinct_shots.append(above_threshold[0])\n",
    "            for i in range(1, len(above_threshold)):\n",
    "                #if within 5ms of each other, assume from same shot\n",
    "                if above_threshold[i] - above_threshold[i-1] > 0.05*22050:\n",
    "                    distinct_shots.append(above_threshold[i])\n",
    "\n",
    "            #times relative to beginning of the saved clip\n",
    "            logger.debug(\"There were \" + str(len(distinct_shots)) + \" distinct shots detected at \" + str(time.ctime(time_of_sample_occurrence)))\n",
    "            for i in distinct_shots:\n",
    "                logger.debug(i/22050)\n",
    "                times_of_shots.append(time_of_sample_occurrence + i/22050)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            #update booleans w detection state \n",
    "            if not detected:\n",
    "                detected = True\n",
    "                detected_first = True\n",
    "            else:\n",
    "                detected_first = False\n",
    "                detected_again = True\n",
    "                    \n",
    "        else:\n",
    "            #update booleans w detection state\n",
    "            if detected:\n",
    "                end_of_detections = True\n",
    "            else:\n",
    "                end_of_detections = False\n",
    "            detected = False\n",
    "            detected_first = False\n",
    "            detected_again = False\n",
    "            \n",
    "    else:\n",
    "        #update booleans w detection state\n",
    "        if detected:\n",
    "            end_of_detections = True\n",
    "        else:\n",
    "            end_of_detections = False\n",
    "        detected = False\n",
    "        detected_first = False\n",
    "        detected_again = False\n",
    "        \n",
    "     #based on booleans, put microphone data or partial mic data on the time localization queue\n",
    "    if detected_first:\n",
    "        localization_data_queue.put(microphone_data)\n",
    "        localization_time_queue.put(time_of_sample_occurrence)\n",
    "    if detected_again:\n",
    "        localization_data_queue.put(microphone_data[66150:]) #just the last half second\n",
    "    if end_of_detections:\n",
    "        localization_data_queue.put(microphone_data[66150:]) #just the last half second\n",
    "        localization_data_queue.put(np.zeros((44100,), dtype = np.int16))\n",
    "        end_of_detections = False\n",
    "            \n",
    "            \n",
    "    #get a new 2 second long sample\n",
    "    #get rid of the first half a second of current microphone data\n",
    "    microphone_data = microphone_data[22050:]\n",
    "    #get a new half second from the queue to add onto the end\n",
    "    microphone_data = np.append(microphone_data, np.array(audio_analysis_queue.get(), dtype = \"int16\"))\n",
    "    #get a new time for the new beginning from the time queue\n",
    "    time_of_sample_occurrence = audio_analysis_time_queue.get()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# shots: 14\n",
      "# distinct shots: 5\n",
      "all:\n",
      "1562621802.3592997\n",
      "1562621802.3810155\n",
      "1562621802.4165487\n",
      "1562621802.4866014\n",
      "1562621802.5083172\n",
      "1562621802.5438504\n",
      "1562621802.5930412\n",
      "1562621802.614757\n",
      "1562621802.6502903\n",
      "1562621802.719481\n",
      "1562621802.7411969\n",
      "1562621802.77673\n",
      "1562621804.3456922\n",
      "1562621805.2138555\n",
      "distinct:\n",
      "1562621802.3592997\n",
      "1562621802.4866014\n",
      "1562621802.719481\n",
      "1562621804.3456922\n",
      "1562621805.2138555\n"
     ]
    }
   ],
   "source": [
    "times_of_shots.sort()\n",
    "\n",
    "times_of_distinct_shots = []\n",
    "times_of_distinct_shots.append(times_of_shots[0])\n",
    "j = 0\n",
    "\n",
    "for i in range(1, len(times_of_shots)):\n",
    "    #print(\"diff from before:\" times_of_shots[i] - times_of_shots[i-1])\n",
    "    #print(times_of_shots[i] - times_of_distinct_shots[j])\n",
    "    if times_of_shots[i] - times_of_shots[i-1] > 0.05:\n",
    "        times_of_distinct_shots.append(times_of_shots[i])\n",
    "        j += 1\n",
    "        \n",
    "        \n",
    "print(\"# shots: \" + str(len(times_of_shots)))\n",
    "print(\"# distinct shots: \" + str(len(times_of_distinct_shots)))\n",
    "\n",
    "print(\"all:\")\n",
    "for a in times_of_shots:\n",
    "    print(a)\n",
    "    \n",
    "print(\"distinct:\")\n",
    "for b in times_of_distinct_shots:\n",
    "    print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing A Model with Sample Audio (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model_one(\"./models/gunshot_sound_model.h5\")\n",
    "# training_sample, sr = librosa.load(\"./recordings/260600_8.wav\")\n",
    "# training_sample = normalize(training_sample)\n",
    "# number_of_missing_hertz = 44100 - len(training_sample)\n",
    "# training_sample = np.array(training_sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "# training_sample = training_sample.reshape(-1, 44100, 1)\n",
    "# probabilities = model.predict(training_sample)\n",
    "# logger.debug(\"The model-predicted probability values: \" + str(probabilities[0]))\n",
    "# logger.debug(\"Model-predicted sample class: \" + label_binarizer.inverse_transform(probabilities[:, 0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
