{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "import six\n",
    "from array import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers, backend as K\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUNSHOT_FREQUENCY_THESHOLD = 0.25\n",
    "SAMPLE_RATE_PER_SECOND = 22050\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100\n",
    "SOUND_FILE_ID = 0\n",
    "MAXIMUM_AUDIO_FRAME_INTEGER_VALUE = 2 ** 15 - 1\n",
    "SOUND_NORMALIZATION_THRESHOLD = 10 ** (-1.0 / 20)\n",
    "BASE_DIRECTORY = \"/home/alexm/Datasets/\"\n",
    "DATA_DIRECTORY = BASE_DIRECTORY + \"REU_Samples_and_Labels/\"\n",
    "SPECTROGRAM_DIRECTORY = BASE_DIRECTORY + \"Spectrograms/\"\n",
    "SOUND_DATA_DIRECTORY = DATA_DIRECTORY + \"Samples/\"\n",
    "samples = []\n",
    "labels = []\n",
    "sound_file_names = []\n",
    "sample_weights = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the CSV file of descriptors for many kinds of sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_types = pd.read_csv(DATA_DIRECTORY + \"labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in all of the sound data WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...Parsing sound data...\")\n",
    "\n",
    "for file in os.listdir(SOUND_DATA_DIRECTORY):\n",
    "    if file.endswith(\".wav\"):\n",
    "        try:\n",
    "            # Adding 2 second-long samples to the list of samples\n",
    "            SOUND_FILE_ID = int(re.search(r'\\d+', file).group())\n",
    "            sample, sample_rate = librosa.load(SOUND_DATA_DIRECTORY + file)\n",
    "            prescribed_label = sound_types.loc[sound_types[\"ID\"] == SOUND_FILE_ID, \"Class\"].values[0]\n",
    "            \n",
    "            if len(sample) <= SAMPLE_RATE_PER_TWO_SECONDS:\n",
    "                label = 1\n",
    "                number_of_missing_hertz = SAMPLE_RATE_PER_TWO_SECONDS - len(sample)\n",
    "                padded_sample = np.array(sample.tolist() + [0 for i in range(number_of_missing_hertz)])\n",
    "                \n",
    "                if prescribed_label != \"gun_shot\":\n",
    "                    label = 0\n",
    "\n",
    "                samples.append(padded_sample)\n",
    "                labels.append(label)\n",
    "                sound_file_names.append(file)\n",
    "                \n",
    "            else:\n",
    "                for i in range(0, sample.size - SAMPLE_RATE_PER_TWO_SECONDS, SAMPLE_RATE_PER_TWO_SECONDS):\n",
    "                    label = 1\n",
    "                    sample_slice = sample[i : i + SAMPLE_RATE_PER_TWO_SECONDS]\n",
    "                    \n",
    "                    if prescribed_label != \"gun_shot\":\n",
    "                        label = 0\n",
    "                        \n",
    "                    elif np.max(abs(sample_slice)) < GUNSHOT_FREQUENCY_THESHOLD:\n",
    "                        label = 0\n",
    "\n",
    "                    samples.append(sample_slice)\n",
    "                    labels.append(label)\n",
    "                    sound_file_names.append(file)\n",
    "\n",
    "        except:\n",
    "            sample, sample_rate = soundfile.read(SOUND_DATA_DIRECTORY + file)\n",
    "            print(\"Sound(s) not recognized by Librosa:\", file)\n",
    "            pass\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching NumPy arrays as NumPy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(BASE_DIRECTORY + \"gunshot_sound_samples.npy\", samples)\n",
    "np.save(BASE_DIRECTORY + \"gunshot_sound_labels.npy\", labels)\n",
    "np.save(BASE_DIRECTORY + \"gunshot_sound_file_names.npy\", sound_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NumPy files as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + \"gunshot_sound_samples.npy\")\n",
    "labels = np.load(BASE_DIRECTORY + \"gunshot_sound_labels.npy\")\n",
    "sound_file_names = np.load(BASE_DIRECTORY + \"gunshot_sound_file_names.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound_data):\n",
    "    absolute_maximum_sound_datum = max(abs(i) for i in sound_data)\n",
    "    \n",
    "    # Prevents a divide by zero scenario\n",
    "    if absolute_maximum_sound_datum == 0.0:\n",
    "        absolute_maximum_sound_datum = 0.001\n",
    "    \n",
    "    normalization_factor = float(SOUND_NORMALIZATION_THRESHOLD * MAXIMUM_AUDIO_FRAME_INTEGER_VALUE) / absolute_maximum_sound_datum\n",
    "    \n",
    "    # Averages the volume out\n",
    "    r = array('f')\n",
    "    for datum in sound_data:\n",
    "        r.append(int(datum * normalization_factor))\n",
    "    return np.array(r, dtype = np.float32)\n",
    "\n",
    "def time_shift(wav):\n",
    "    start_ = int(np.random.uniform(-7000, 7000))\n",
    "    if start_ >= 0:\n",
    "        wav_time_shift = np.r_[wav[start_:], np.random.uniform(-0.001, 0.001, start_)]\n",
    "    else:\n",
    "        wav_time_shift = np.r_[np.random.uniform(-0.001, 0.001, -start_), wav[:start_]]\n",
    "    return wav_time_shift\n",
    "    \n",
    "def change_pitch(wav, sample_rate):\n",
    "    magnitude = (np.random.uniform(-0.1, 0.1))\n",
    "    wav_pitch_change = librosa.effects.pitch_shift(wav, sample_rate, magnitude)\n",
    "    return wav_pitch_change\n",
    "    \n",
    "def speed_change(wav):\n",
    "    speed_rate = np.random.uniform(0.7, 1.3)\n",
    "    wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "    \n",
    "    if len(wav_speed_tune) < len(wav):\n",
    "        pad_len = len(wav) - len(wav_speed_tune)\n",
    "        wav_speed_tune = np.r_[np.random.uniform(-0.0001, 0.0001, int(pad_len / 2)),\n",
    "                               wav_speed_tune,\n",
    "                               np.random.uniform(-0.0001, 0.0001, int(np.ceil(pad_len / 2)))]\n",
    "    else: \n",
    "        cut_len = len(wav_speed_tune) - len(wav)\n",
    "        wav_speed_tune = wav_speed_tune[int(cut_len / 2) : int(cut_len / 2) + len(wav)]\n",
    "    return wav_speed_tune\n",
    "    \n",
    "def change_volume(wav, magnitude):\n",
    "    # 0 < x < 1 quieter; x = 1 identity; x > 1 louder\n",
    "    wav_volume_change = np.multiply(np.array([magnitude]), wav)\n",
    "    return wav_volume_change\n",
    "    \n",
    "def add_background(wav, file, data_directory, label_to_avoid):\n",
    "    label_csv = data_directory + \"labels.csv\"\n",
    "    sound_types = pd.read_csv(label_csv)\n",
    "    sound_directory = data_directory + \"Samples/\"\n",
    "    bg_files = os.listdir(sound_directory)\n",
    "    bg_files.remove(file)\n",
    "    chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "    jndex = int(chosen_bg_file.split('.')[0])\n",
    "    while sound_types.loc[sound_types[\"ID\"] == jndex, \"Class\"].values[0] == label_to_avoid:\n",
    "        chosen_bg_file = bg_files[np.random.randint(len(bg_files))]\n",
    "        jndex = int(chosen_bg_file.split('.')[0])\n",
    "    bg, sr = librosa.load(sound_directory + chosen_bg_file)\n",
    "    ceil = max((bg.shape[0] - wav.shape[0]), 1)\n",
    "    start_ = np.random.randint(ceil)\n",
    "    bg_slice = bg[start_ : start_ + wav.shape[0]]\n",
    "    if bg_slice.shape[0] < wav.shape[0]:\n",
    "        pad_len = wav.shape[0] - bg_slice.shape[0]\n",
    "        bg_slice = np.r_[np.random.uniform(-0.001, 0.001, int(pad_len / 2)), bg_slice, np.random.uniform(-0.001, 0.001, int(np.ceil(pad_len / 2)))]\n",
    "    wav_with_bg = wav * np.random.uniform(0.8, 1.2) + bg_slice * np.random.uniform(0, 0.5)\n",
    "    return wav_with_bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting data (i.e. time shifting, speed changing, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "number_of_augmentations = 5\n",
    "augmented_samples = np.zeros((samples.shape[0] * (number_of_augmentations + 1), samples.shape[1]))\n",
    "augmented_labels = np.zeros((labels.shape[0] * (number_of_augmentations + 1),))\n",
    "augmented_sound_file_names = []\n",
    "j = 0\n",
    "\n",
    "for i in range (0, len(augmented_samples), (number_of_augmentations + 1)):\n",
    "    file = sound_file_names[j]\n",
    "    \n",
    "    augmented_samples[i,:] = samples[j,:]\n",
    "    augmented_samples[i + 1,:] = time_shift(samples[j,:])\n",
    "    augmented_samples[i + 2,:] = change_pitch(samples[j,:], SAMPLE_RATE_PER_SECOND)\n",
    "    augmented_samples[i + 3,:] = speed_change(samples[j,:])\n",
    "    augmented_samples[i + 4,:] = change_volume(samples[j,:], np.random.uniform())\n",
    "    if labels[j] == 1:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], file, DATA_DIRECTORY, \"\") \n",
    "    else:\n",
    "        augmented_samples[i + 5,:] = add_background(samples[j,:], file, DATA_DIRECTORY, \"gun_shot\")\n",
    "    \n",
    "    augmented_labels[i] = labels[j]\n",
    "    augmented_labels[i + 1] = labels[j]\n",
    "    augmented_labels[i + 2] = labels[j]\n",
    "    augmented_labels[i + 3] = labels[j]\n",
    "    augmented_labels[i + 4] = labels[j]\n",
    "    augmented_labels[i + 5] = labels[j]\n",
    "    \n",
    "    augmented_sound_file_names.append(file)\n",
    "    augmented_sound_file_names.append(file)\n",
    "    augmented_sound_file_names.append(file)\n",
    "    augmented_sound_file_names.append(file)\n",
    "    augmented_sound_file_names.append(file)\n",
    "    augmented_sound_file_names.append(file)\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "samples = augmented_samples\n",
    "labels = augmented_labels\n",
    "sound_file_names = np.array(augmented_sound_file_names)\n",
    "\n",
    "\n",
    "print(\"The number of samples available for training is currently \" + str(len(samples)) + '.')\n",
    "print(\"The number of labels available for training is currently \" + str(len(labels)) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving augmented NumPy arrays as NumPy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(BASE_DIRECTORY + \"gunshot_augmented_sound_samples.npy\", samples)\n",
    "np.save(BASE_DIRECTORY + \"gunshot_augmented_sound_labels.npy\", labels)\n",
    "np.save(BASE_DIRECTORY + \"gunshot_augmented_sound_file_names.npy\", sound_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading augmented NumPy files as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_samples.npy\")\n",
    "labels = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_labels.npy\")\n",
    "sound_file_names = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_file_names.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating a sample weights NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([1 for normally_recorded_sample in range(len(samples) - 660)] + [50 for raspberry_pi_recorded_sample in range(660)])\n",
    "print(\"Shape of samples weights before splitting:\", sample_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging after augmenting the data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample = samples[i]\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate = SAMPLE_RATE_PER_SECOND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting augmented samples to spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining spectrogram conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spectrogram(data, sample_rate):\n",
    "    return np.array(librosa.feature.melspectrogram(y = data, sr = sample_rate), dtype = \"float32\")\n",
    "\n",
    "\n",
    "def power_to_db(S, ref = 1.0, amin = 1e-10, top_db = 80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug('ParameterError: amin must be strictly positive')\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug('Warning: power_to_db was called on complex input so phase '\n",
    "                      'information will be discarded. To suppress this warning, '\n",
    "                      'call power_to_db(np.abs(D)**2) instead.')\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug('ParameterError: top_db must be non-negative')\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def convert_spectrogram_to_image(spectrogram):\n",
    "    plt.interactive(False)\n",
    "    \n",
    "    figure = plt.figure(figsize = [0.72, 0.72], dpi = 400)\n",
    "    plt.tight_layout(pad = 0)\n",
    "    ax = figure.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    librosa.display.specshow(power_to_db(spectrogram, ref = np.max))\n",
    "    \n",
    "    canvas = FigureCanvas(figure)\n",
    "    canvas.draw()\n",
    "    s, (width, height) = canvas.print_to_buffer()\n",
    "\n",
    "    image = np.fromstring(figure.canvas.tostring_rgb(), dtype = \"uint8\")\n",
    "    image = image.reshape((width, height, 3))\n",
    "    image = cv2.resize(image, (192, 192))\n",
    "\n",
    "    # Cleaning up the matplotlib instance\n",
    "    plt.close()    \n",
    "    figure.clf()\n",
    "    plt.close(figure)\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    # Returns a NumPy array containing an image of a spectrogram\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively converting all augmented samples into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = []\n",
    "\n",
    "for sample in samples:\n",
    "    sample = normalize(sample)  # Normalizes augmented samples after loading them\n",
    "    spectrogram = convert_to_spectrogram(sample, SAMPLE_RATE_PER_SECOND)\n",
    "    spectrogram = convert_spectrogram_to_image(spectrogram)\n",
    "    spectrograms.append(spectrogram)\n",
    "    print(\"Converted a sample into a spectrogram...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(spectrograms).reshape(-1, 192, 192, 3)\n",
    "samples = samples.astype(\"float32\")\n",
    "samples /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving spectrograms as a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(BASE_DIRECTORY + \"gunshot_augmented_sample_spectrograms.npy\", samples)\n",
    "print(\"Successfully saved all spectrograms as a NumPy array...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a NumPy file as spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + \"gunshot_augmented_sample_spectrograms.npy\")\n",
    "print(\"Successfully loaded all spectrograms as a NumPy array...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of the sample and label data's shape (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of samples array:\", samples.shape)\n",
    "print(\"Shape of labels array:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 3, shuffle = True)\n",
    "for train_index, test_index in kf.split(samples):\n",
    "    train_wav, test_wav = samples[train_index], samples[test_index]\n",
    "    train_label, test_label = labels[train_index], labels[test_index]\n",
    "    train_weights, test_weights = sample_weights[train_index], sample_weights[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(BASE_DIRECTORY + \"gunshot_2d_spectrogram_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 100\n",
    "batch_size = 32\n",
    "optimizer = Adam(lr = 0.001, decay = 0.001 / 100)\n",
    "input_tensor = Input(shape = (192, 192))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of GPU for training (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 1: Instantiate a sequential model \"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\"\"\" Step 2: Create the input and hidden layers \"\"\"\n",
    "\n",
    "# First Layer\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", input_shape = (192, 192, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second Layer: (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third Layer: (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth Layer: (CONV => RELU) * 2 => POOL\n",
    "model.add(Conv2D(256, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Conv2D(256, (3, 3), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\"\"\" Step 3: Flatten the layers \"\"\"\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\"\"\" Step 4: Fully-connect the layers \"\"\"\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  # Increasing dropout here to prevent overfitting\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "\"\"\" Step 5: Compile the model \"\"\"\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [auc, \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = BASE_DIRECTORY + \"gunshot_2d_spectrogram_model.pkl\"\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor = \"val_acc\",\n",
    "                  patience = 15,\n",
    "                  verbose = 1,\n",
    "                  mode = \"max\"),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor = \"val_acc\",\n",
    "                    verbose = 1,\n",
    "                    save_best_only = True,\n",
    "                    mode = \"max\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of the model's architecture (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & caching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data = [test_wav, test_label],\n",
    "          epochs = number_of_epochs,\n",
    "          callbacks = model_callbacks,\n",
    "          verbose = 1,\n",
    "          batch_size = batch_size,\n",
    "          sample_weight = train_weights,\n",
    "          shuffle = True)\n",
    "\n",
    "model.save(BASE_DIRECTORY + \"gunshot_2d_spectrogram_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history[\"acc\"])\n",
    "plt.plot(History.history[\"val_acc\"])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of incorrectly-labeled examples (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_wav)\n",
    "y_predicted_classes_test = y_test_pred.argmax(axis = -1)\n",
    "y_actual_classes_test = test_label.argmax(axis = -1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_test != y_actual_classes_test)\n",
    "print(wrong_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of an individual incorrectly-labeled example (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sample = np.reshape(test_wav[i], SAMPLE_RATE_PER_TWO_SECONDS, )\n",
    "sample_rate = 22050\n",
    "print(y_actual_classes_test[i], y_predicted_classes_test[i])\n",
    "ipd.Audio(sample, rate = SAMPLE_RATE_PER_SECOND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting labels to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_binarizer.inverse_transform(labels[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting model to TensorFlow Lite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = BASE_DIRECTORY + \"gunshot_2d_spectrogram_model\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(model_name + \".h5\", custom_objects = {\"auc\" : auc})\n",
    "converter.post_training_quantize = True\n",
    "tflite_model = converter.convert()\n",
    "open(model_name + \".tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gunshot_detection",
   "language": "python",
   "name": "gunshot_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
