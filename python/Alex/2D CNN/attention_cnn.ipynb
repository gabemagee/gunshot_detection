{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Directory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import re\n",
    "import cv2\n",
    "import six\n",
    "from array import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import kutilities.layers as kutil_layers\n",
    "from tensorflow.keras import Input, layers, backend as K\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Dropout, Activation, BatchNormalization, Flatten, Lambda, Concatenate, Model, noise\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUNSHOT_FREQUENCY_THESHOLD = 0.25\n",
    "SAMPLE_RATE_PER_SECOND = 22050\n",
    "SAMPLE_RATE_PER_TWO_SECONDS = 44100\n",
    "HOP_LENGTH = 345 * 2\n",
    "MINIMUM_FREQUENCY = 20\n",
    "MAXIMUM_FREQUENCY = SAMPLE_RATE_PER_SECOND\n",
    "NUMBER_OF_MELS = 128\n",
    "NUMBER_OF_FFTS = NUMBER_OF_MELS * 20\n",
    "BASE_DIRECTORY = \"/home/alexm/Datasets/\"\n",
    "DATA_DIRECTORY = BASE_DIRECTORY + \"REU_Samples_and_Labels/\"\n",
    "SPECTROGRAM_DIRECTORY = BASE_DIRECTORY + \"Spectrograms/\"\n",
    "SOUND_DATA_DIRECTORY = DATA_DIRECTORY + \"Samples/\"\n",
    "samples = []\n",
    "labels = []\n",
    "sound_file_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading augmented NumPy files as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_samples.npy\")\n",
    "labels = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_labels.npy\")\n",
    "sound_file_names = np.load(BASE_DIRECTORY + \"gunshot_augmented_sound_file_names.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating a sample weights NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([1 for normally_recorded_sample in range(len(samples) - 660)] + [20 for raspberry_pi_recorded_sample in range(660)])\n",
    "print(\"Shape of samples weights before splitting:\", sample_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging after augmenting the data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # You can change the value of 'i' to adjust which sample is being inspected.\n",
    "sample = samples[i]\n",
    "print(\"The number of samples available to the model for training is \" + str(len(samples)) + '.')\n",
    "print(\"The maximum frequency value in sample slice #\" + str(i) + \" is \" + str(np.max(abs(sample))) + '.')\n",
    "print(\"The label associated with sample slice #\" + str(i) + \" is \" + str(labels[i]) + '.')\n",
    "ipd.Audio(sample, rate = SAMPLE_RATE_PER_SECOND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting augmented samples to spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining spectrogram conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_spectrogram(data):\n",
    "    spectrogram = librosa.feature.melspectrogram(y=data, sr=SAMPLE_RATE_PER_TWO_SECONDS,\n",
    "                                                 hop_length=HOP_LENGTH,\n",
    "                                                 fmin=MINIMUM_FREQUENCY,\n",
    "                                                 fmax=MAXIMUM_FREQUENCY,\n",
    "                                                 n_mels=NUMBER_OF_MELS,\n",
    "                                                 n_fft=NUMBER_OF_FFTS)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    S = np.asarray(S)\n",
    "    if amin <= 0:\n",
    "        logger.debug(\"ParameterError: amin must be strictly positive\")\n",
    "    if np.issubdtype(S.dtype, np.complexfloating):\n",
    "        logger.debug(\"Warning: power_to_db was called on complex input so phase information will be discarded.\")\n",
    "        magnitude = np.abs(S)\n",
    "    else:\n",
    "        magnitude = S\n",
    "    if six.callable(ref):\n",
    "        # User supplied a function to calculate reference power\n",
    "        ref_value = ref(magnitude)\n",
    "    else:\n",
    "        ref_value = np.abs(ref)\n",
    "    log_spec = 10.0 * np.log10(np.maximum(amin, magnitude))\n",
    "    log_spec -= 10.0 * np.log10(np.maximum(amin, ref_value))\n",
    "    if top_db is not None:\n",
    "        if top_db < 0:\n",
    "            logger.debug(\"ParameterError: top_db must be non-negative\")\n",
    "        log_spec = np.maximum(log_spec, log_spec.max() - top_db)\n",
    "    return log_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively converting all augmented samples into spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = []\n",
    "\n",
    "for sample in samples:\n",
    "    spectrogram = convert_audio_to_spectrogram(sample)\n",
    "    spectrograms.append(spectrogram)\n",
    "    print(\"Converted a sample into a spectrogram...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.array(spectrograms).reshape(-1, 192, 192, 3)\n",
    "samples = samples.astype(\"float32\")\n",
    "samples /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving spectrograms as a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(BASE_DIRECTORY + \"gunshot_augmented_sample_spectrograms.npy\", samples)\n",
    "print(\"Successfully saved all spectrograms as a NumPy array...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a NumPy file as spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(BASE_DIRECTORY + \"gunshot_augmented_sample_spectrograms.npy\")\n",
    "print(\"Successfully loaded all spectrograms as a NumPy array...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing index values for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = np.arange(len(samples))\n",
    "train_index = np.load(\"../../raspberry_pi/indexes/training_set_indexes.npy\")\n",
    "test_index = np.load(\"../../raspberry_pi/indexes/testing_set_indexes.npy\")\n",
    "valid_index = np.delete(all_index, list(train_index) + list(test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring the label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([(\"gun_shot\" if label == 1 else \"other\") for label in labels])\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = np.hstack((labels, 1 - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of the sample and label data's shape (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of samples array:\", samples.shape)\n",
    "print(\"Shape of labels array:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wav, test_wav, valid_wav = samples[train_index], samples[test_index], samples[valid_index]\n",
    "train_label, test_label, valid_label = labels[train_index], labels[test_index], labels[valid_index]\n",
    "train_weights, test_weights, valid_weights = sample_weights[train_index], sample_weights[test_index], sample_weights[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (AUC) metric - Uses the import \"from tensorflow.keras import backend as K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosschannelnormalization(alpha = 1e-4, k = 2, beta = 0.75, n = 5,**kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        b, ch, r, c = X.shape\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0,2,3,1))\n",
    "                                              , (0,half))\n",
    "        extra_channels = K.permute_dimensions(extra_channels, (0,3,1,2))\n",
    "        scale = k\n",
    "        for i in range(n):\n",
    "            scale += alpha * extra_channels[:,i:i+ch,:,:]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape:input_shape,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_average_pooling(x):\n",
    "    return K.mean(x, axis = (2, 3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    return input_shape[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_control(args):\n",
    "    x, dense_2 = args\n",
    "    find_att = K.reshape(x, (15,15,10))\n",
    "    find_att = K.transpose(find_att[:,:,:])\n",
    "    find_att = K.mean(find_att, axis = 0)\n",
    "    find_att = find_att / K.sum(find_att, axis = 0)\n",
    "    find_att = K.repeat_elements(find_att, 32, axis = 0)\n",
    "    find_att = K.reshape(find_att, (1, 32, 15, 15))\n",
    "    return find_att\n",
    "\n",
    "def no_attention_control(args):\n",
    "    x, dense_2 = args\n",
    "    find_att = K.ones(shape = (1, 32, 15, 15))\n",
    "    return find_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shape1(x):\n",
    "    x = K.reshape(K.transpose(x), (15 * 15, 32))\n",
    "    return x\n",
    "\n",
    "def att_shape(input_shape):\n",
    "    return (input_shape[0][0], 32, 15, 15)\n",
    "\n",
    "def att_shape2(input_shape):\n",
    "    return input_shape[0][0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 100\n",
    "batch_size = 32\n",
    "optimizer = Adam(lr = 0.001, decay = 0.001 / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of GPU for training (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_cnn(inc_noise = False, attention = True):\n",
    "    # Make layers\n",
    "    inputs = Input(shape = (1, image_size, image_size), name='input')\n",
    "\n",
    "    conv_1a = Convolution2D(32, 3, 3, activation='relu', name='conv_1')\n",
    "    maxp_1a = MaxPooling2D((3, 3), strides = (2,2), name = 'convmax_1')\n",
    "    norm_1a = crosschannelnormalization(name = \"convpool_1\")\n",
    "    zero_1a = ZeroPadding2D((2,2), name = 'convzero_1')\n",
    "\n",
    "    conv_2a = Convolution2D(32, 3, 3, activation = 'relu', name = 'conv_2')\n",
    "    maxp_2a = MaxPooling2D((3, 3), strides = (2,2), name = 'convmax_2')\n",
    "    norm_2a = crosschannelnormalization(name = \"convpool_2\")\n",
    "    zero_2a = ZeroPadding2D((2,2), name = 'convzero_2')\n",
    "\n",
    "    dense_1a = Lambda(global_average_pooling, output_shape = global_average_pooling_shape, name='dense_1')\n",
    "    dense_2a = Dense(10, activation = 'softmax', init = 'uniform', name = 'dense_2')\n",
    "\n",
    "    # Make actual model\n",
    "    if inc_noise:\n",
    "        inputs_noise = noise.GaussianNoise(2.5)(inputs)\n",
    "        input_pad = ZeroPadding2D((1,1), input_shape = (1, image_size, image_size), name = 'input_pad')(inputs_noise)\n",
    "    else:\n",
    "        input_pad = ZeroPadding2D((1,1), input_shape = (1, image_size, image_size), name = 'input_pad')(inputs)\n",
    "\n",
    "    conv_1 = conv_1a(input_pad)\n",
    "    conv_1 = maxp_1a(conv_1)\n",
    "    conv_1 = norm_1a(conv_1)\n",
    "    conv_1 = zero_1a(conv_1)\n",
    "\n",
    "    conv_2_x = conv_2a(conv_1)\n",
    "    conv_2 = maxp_2a(conv_2_x)\n",
    "    conv_2 = norm_2a(conv_2)\n",
    "    conv_2 = zero_2a(conv_2)\n",
    "    conv_2 = Dropout(0.5)(conv_2)\n",
    "\n",
    "    dense_1 = dense_1a(conv_2)\n",
    "    dense_2 = dense_2a(dense_1)\n",
    "\n",
    "    conv_shape1 = Lambda(change_shape1,output_shape = (32,), name = 'chg_shape')(conv_2_x)\n",
    "    find_att = dense_2a(conv_shape1)\n",
    "\n",
    "    if attention:\n",
    "        find_att = Lambda(attention_control, output_shape = att_shape,name = 'att_con')([find_att,dense_2])\n",
    "    else:\n",
    "        find_att = Lambda(no_attention_control, output_shape = att_shape, name = 'att_con')([find_att,dense_2])\n",
    "\n",
    "    zero_3a = ZeroPadding2D((1,1), name = 'convzero_3')(find_att)\n",
    "    apply_attention = Concatenate(mode = 'mul', name = 'attend')([zero_3a, conv_1])\n",
    "    \n",
    "    conv_3 = conv_2a(apply_attention)\n",
    "    conv_3 = maxp_2a(conv_3)\n",
    "    conv_3 = norm_2a(conv_3)\n",
    "    conv_3 = zero_2a(conv_3)\n",
    "\n",
    "    dense_3 = dense_1a(conv_3)\n",
    "    dense_4 = dense_2a(dense_3)\n",
    "\n",
    "    model = Model(input = inputs, output = dense_4)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = attention_cnn(inc_noise = False)\n",
    "model.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [auc, \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = BASE_DIRECTORY + \"2D_attention_cnn.pkl\"\n",
    "\n",
    "model_callbacks = [\n",
    "    EarlyStopping(monitor = \"val_acc\",\n",
    "                  patience = 15,\n",
    "                  verbose = 1,\n",
    "                  mode = \"max\"),\n",
    "    \n",
    "    ModelCheckpoint(model_filename, monitor = \"val_acc\",\n",
    "                    verbose = 1,\n",
    "                    save_best_only = True,\n",
    "                    mode = \"max\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of the model's architecture (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & caching the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History = model.fit(train_wav, train_label, \n",
    "          validation_data = [test_wav, test_label],\n",
    "          epochs = number_of_epochs,\n",
    "          callbacks = model_callbacks,\n",
    "          verbose = 1,\n",
    "          batch_size = batch_size,\n",
    "          sample_weight = train_weights,\n",
    "          shuffle = True)\n",
    "\n",
    "model.save(BASE_DIRECTORY + \"2D_attention_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging of incorrectly-labeled examples (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(valid_wav)\n",
    "y_predicted_classes_val = y_val_pred.argmax(axis=-1)\n",
    "y_actual_classes_val = valid_label.argmax(axis=-1)\n",
    "wrong_examples = np.nonzero(y_predicted_classes_val != y_actual_classes_val)\n",
    "print(\"Validation samples labeled incorrectly:\", wrong_examples)\n",
    "print(\"Validation accuracy of the current model:\", 100 - (len(wrong_examples[0]) / len(valid_wav)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting model to TensorFlow Lite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = BASE_DIRECTORY + \"gunshot_2d_spectrogram_model\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(model_name + \".h5\", custom_objects = {\"auc\" : auc})\n",
    "tflite_model = converter.convert()\n",
    "open(model_name + \".tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
